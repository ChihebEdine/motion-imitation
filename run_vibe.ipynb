{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7-kq68SPwN0a"
   },
   "source": [
    "# Pose Detection from Youtube Instructional video with VIBE\n",
    "\n",
    "This notebook uses the open-source project [/mkocabas/VIBE](https://github.com/mkocabas/VIBE) to detect person shape and pose from instructional videos from Youtube.\n",
    "\n",
    "It is inspired from [/tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb) and makes use of  [youtube-dl program](https://github.com/ytdl-org/youtube-dl) to load and extract frames from Youtube videos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyXuMGGzY0Yp"
   },
   "source": [
    "## Install Vibe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Tvd4cfPk5a0e",
    "outputId": "35cf84c3-d369-4877-cc69-ea9e08bd2555"
   },
   "outputs": [],
   "source": [
    "# Clone the repo\n",
    "!git clone https://github.com/mkocabas/VIBE.git\n",
    "\n",
    "%cd VIBE/\n",
    "\n",
    "# Install the other requirements\n",
    "!pip install torch==1.4.0 numpy==1.17.5\n",
    "!pip install git+https://github.com/giacaglia/pytube.git --upgrade\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Download pretrained weights and SMPL data\n",
    "!source scripts/prepare_data.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSyLMjvaaX8S"
   },
   "source": [
    "# Load Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "YOJimmxNXzQh",
    "outputId": "c66bf69e-c54b-4afc-cfa8-55fcf756e7f7"
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YOUTUBE_ID = 'Ae3AkGYpWsM'  # 00:17 \n",
    "YouTubeVideo(YOUTUBE_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGgiZXI5ZuT_",
    "outputId": "6cac165a-aea8-4b81-b893-ab35c468b7ea"
   },
   "outputs": [],
   "source": [
    "# install python dependencies\n",
    "!pip install -q youtube-dl\n",
    "\n",
    "!rm -rf youtube.mp4\n",
    "\n",
    "# download the youtube with the given ID\n",
    "!youtube-dl -f 'bestvideo[ext=mp4]' --output \"youtube.%(ext)s\" https://www.youtube.com/watch?v=$YOUTUBE_ID\n",
    "\n",
    "# cut the first 7 seconds, starting from the second 36\n",
    "!ffmpeg -y -loglevel info -i youtube.mp4 -ss 00:00:36 -t 7 video.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7CLAhFiahb8"
   },
   "source": [
    "# Apply VIBE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4vllMkw2DyB"
   },
   "source": [
    "To apply VIBE, we run the [VIBE/demo.py](https://github.com/mkocabas/VIBE/blob/master/demo.py) with the default **bbox** tracking method and **Yolo** detector as it gives a good tradeoff between speed and accuracy. \n",
    "\n",
    "Please refer to [VIBE/demo.md](https://github.com/mkocabas/VIBE/blob/master/doc/demo.md) for further details about the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_oGFDSyVawwU",
    "outputId": "fe2781c3-12cd-4ca6-bd65-a1f5bb2887e5"
   },
   "outputs": [],
   "source": [
    "%cd /content/VIBE\n",
    "\n",
    "!python demo.py --vid_file video.mp4 --output_folder ../"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pj_hlIDbbZF7"
   },
   "source": [
    "# Show results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2HXWJ8SRYl5-"
   },
   "outputs": [],
   "source": [
    "# this function is borrowed from https://github.com/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb\n",
    "def show_local_mp4_video(file_name, width=640, height=480):\n",
    "  import io\n",
    "  import base64\n",
    "  from IPython.display import HTML\n",
    "  video_encoded = base64.b64encode(io.open(file_name, 'rb').read())\n",
    "  return HTML(data='''<video width=\"{0}\" height=\"{1}\" alt=\"test\" controls>\n",
    "                        <source src=\"data:video/mp4;base64,{2}\" type=\"video/mp4\" />\n",
    "                      </video>'''.format(width, height, video_encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 741
    },
    "id": "xMAs5lerbCus",
    "outputId": "69b644c2-4c1c-4715-d2fb-5bd982192f65",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_local_mp4_video('/content/video/video_vibe_result.mp4', width=960, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LePW-8-4I6J"
   },
   "source": [
    "## VIBE Output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O2DIQ77b4fk6",
    "outputId": "470fbd35-03d6-471a-b8f5-97039d68579d"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "output = joblib.load('/content/video/vibe_output.pkl')\n",
    "print(output.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tkZIp1dx4wgV",
    "outputId": "e6108011-519f-4349-fb76-5e6c61375f34"
   },
   "outputs": [],
   "source": [
    "for k,v in output[1].items(): \n",
    "  if (k!=\"joints2d\"):\n",
    "    print(k, v.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsEq8Syx4aCT"
   },
   "source": [
    "VIBE outputs  a dictionary associating to each tracked person id a vector of the pose and shape predictions along the frames in SMPL format:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "pred_cam (n_frames, 3)      # weak perspective camera parameters in cropped image space (s,tx,ty)\n",
    "orig_cam (n_frames, 4)      # weak perspective camera parameters in original image space (sx,sy,tx,ty)\n",
    "verts (n_frames, 6890, 3)   # SMPL mesh vertices\n",
    "pose (n_frames, 72)         # SMPL pose parameters\n",
    "betas (n_frames, 10)        # SMPL body shape parameters\n",
    "joints3d (n_frames, 49, 3)  # SMPL 3D joints\n",
    "joints2d (n_frames, 21, 3)  # 2D keypoint detections by STAF if pose tracking enabled otherwise None\n",
    "bboxes (n_frames, 4)        # bbox detections (cx,cy,w,h)\n",
    "frame_ids (n_frames,)       # frame ids in which subject with tracking id #1 appears\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_vibe.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
